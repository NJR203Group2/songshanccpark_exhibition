{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "T3MhTai2S-9M"
      },
      "outputs": [],
      "source": [
        "# 避免沒有相關模組\n",
        "!pip install easyocr google-genai google-api-python-client opencv-python-headless"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B08jfInsNHCh"
      },
      "source": [
        "# Use Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHB4WU7smTIC"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# I. 核心 AI 服務 (Gemini/RAG) & OCR\n",
        "# ====================================================================\n",
        "import cv2                        # 處理圖片 (OCR)\n",
        "import json                       # 處理 JSON 格式\n",
        "from google import genai          # Gemini API\n",
        "from google.genai import types    # Gemini 結構化輸出 Schema\n",
        "from googleapiclient.discovery import build # Google 搜尋 API\n",
        "from google.colab import drive # 授權帳號\n",
        "import easyocr                    # OCR 圖片文字識別\n",
        "from google.genai.errors import APIError # 處理 Gemini API 錯誤\n",
        "\n",
        "# ====================================================================\n",
        "# II. 網路請求 (Web/HTTP) 與解析\n",
        "# ====================================================================\n",
        "from bs4 import BeautifulSoup as bs # HTML 解析\n",
        "import requests as req              # HTTP 請求\n",
        "from urllib.parse import urljoin, urlparse    # URL 組合\n",
        "\n",
        "# ====================================================================\n",
        "# III. 檔案/系統與環境變數管理\n",
        "# ====================================================================\n",
        "import os                         # 讀取環境變數\n",
        "import re                         # 正規表達式\n",
        "from pathlib import Path as pp    # 檔案路徑操作\n",
        "import time                       # 執行延遲\n",
        "from google.colab import userdata  # 載入 Secrets KEY Value：colab環境使用\n",
        "import copy # 檔案處理\n",
        "# ====================================================================\n",
        "# IV. 資料、時間與隨機性\n",
        "# ====================================================================\n",
        "import random as rd               # 隨機延遲時間\n",
        "from datetime import datetime     # 處理日期與時間"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvw3ujd-NYRI"
      },
      "source": [
        "# Function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdsMCSJpNswD"
      },
      "source": [
        "## 展覽基礎資訊爬蟲 - 主要資訊來源"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPBVO_AGNjI-"
      },
      "outputs": [],
      "source": [
        "def baseinfo(pageurl, headers) -> list[dict]:\n",
        "    baseans = [] # 爬出來資訊儲存用\n",
        "    # img_path =[] # 圖片路徑\n",
        "    for ccnt, i in enumerate(pageurl):\n",
        "        infolist = {\n",
        "        'strt_dt': None, # 開始日期\n",
        "        'end_dt': None, # 結束日期\n",
        "        'name': '', # 展覽名稱\n",
        "        'article': '', # 重點敘述\n",
        "        'big_imgurl': '',   # 這裡放圖片的二進制內容，等等每個都放進去辨識內容，取出有用資訊\n",
        "        'loc': '', # 地點\n",
        "        'pagetext': '', # 展覽內容敘述\n",
        "        'pageurl': i, # 展覽內容網址\n",
        "        'pageimgurl': None\n",
        "        }\n",
        "\n",
        "        resi = req.get(i, headers)\n",
        "        soup = bs(resi.text, 'html.parser')\n",
        "\n",
        "        infolist['name'] = soup.select_one('div.news_inner p.inner_title').get_text(strip = True)\n",
        "        infolist['strt_dt']= soup.select_one('div.under > p.montsrt').get_text(strip = True).split(' - ')[0]\n",
        "        infolist['end_dt']= soup.select_one('div.under > p.montsrt').get_text(strip = True).split(' - ')[1]\n",
        "        infolist['article']= soup.select_one('article.big_article').get_text(strip = True)\n",
        "        infolist['big_imgurl']= urljoin(jpgparpath, soup.select_one('img.big_img').get('src'))\n",
        "        infolist['loc']= soup.select_one('p.place').get_text(strip = True)\n",
        "        infolist['pagetext']= soup.select_one('section').get_text('\\n', strip = True)\n",
        "        infolist['pageimgurl'] = [imgtag.get('src') for imgtag in soup.select('section img')]\n",
        "\n",
        "        # col.update_one({'pageurl': infolist['pageurl']}, {'$set': infolist}, upsert = True) # 存進DB\n",
        "        # col.create_index('pageurl', unique = True) # 設定index\n",
        "        # col.create_index([('article', 'text'), ('pagetext', 'text')]) # 設定index > 文字索引\n",
        "        save = (download_img(jpgparpath,\n",
        "                             infolist['big_imgurl'],\n",
        "                             save_dir = str(datetime.strftime(datetime.today(), '%Y_%m_%d')) + '_images', # 新建資料匣，以當天日期做資料匣名稱\n",
        "                             headers = headers,\n",
        "                             img_nm = infolist['name'])) # 圖片下載，並用標題名稱當作檔名\n",
        "        for idx, imgurl in enumerate(infolist['pageimgurl']):\n",
        "            save_inner = (download_img(jpgparpath,\n",
        "                             imgurl,\n",
        "                             save_dir = str(datetime.strftime(datetime.today(), '%Y_%m_%d')) + '_images/' + f'{infolist['name']}', # 新建子資料匣，加入展覽名稱做資料匣名稱\n",
        "                             headers = headers,\n",
        "                             img_nm = urlparse(imgurl).path.split('/')[-1].split('.')[0]))\n",
        "            infolist['pageimgurl'][idx] = save_inner if save_inner else None # 置換外部網址成儲存的內部網址\n",
        "        print(f'[{ccnt + 1}/{len(pageurl)}] {infolist['name']}') # 存進 MongoDB，圖片已下載 {save}\n",
        "        baseans.append(infolist)\n",
        "        time.sleep(rd.randint(1, 15))\n",
        "    return baseans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsNEoFW2Nx1c"
      },
      "source": [
        "## 圖片下載"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3OR8UYcN0id"
      },
      "outputs": [],
      "source": [
        "# ImageDownload Function\n",
        "def download_img(base_url: str,\n",
        "                 img_src: str,\n",
        "                 save_dir: str = 'images',\n",
        "                 headers: dict = None,\n",
        "                 img_nm: str = 'unnamed') -> pp | None:\n",
        "    '''\n",
        "        base_url (str): 網頁的基準網址，用來處理相對路徑 (例: https://example.com/page.html)\n",
        "        img_src (str): <img> 標籤裡的 src\n",
        "        save_dir (str): 存放圖片的資料夾名稱，預設 'images'\n",
        "        headers (dict): requests 的 HTTP 標頭\n",
        "    '''\n",
        "\n",
        "    DEFAULT_USER_AGENT = ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n",
        "    # 檢查user-agent變數\n",
        "    if headers is None:\n",
        "        current_headers = globals().get('hd', {'user-agent': DEFAULT_USER_AGENT})\n",
        "    else:\n",
        "        current_headers = headers\n",
        "\n",
        "    # 把 base_url 和 img_src 合併，確保拿到完整的圖片網址\n",
        "    img_url = urljoin(base_url, img_src)\n",
        "\n",
        "    # 用網頁標題當作檔案名稱，排除掉windows非法的檔名符號\n",
        "    illegal_chars = r'[<>:\"/\\\\|?*．\\s]+'\n",
        "    img_name = img_nm.strip().strip('_')\n",
        "    filename = re.sub(illegal_chars, '_', img_name) + '.jpg'\n",
        "\n",
        "    # 建立存放圖片的資料夾 (如果不存在就建立)\n",
        "    save_path = pp(save_dir)\n",
        "    save_path = filepath / save_path.with_name(re.sub(illegal_chars, '_', save_path.name))\n",
        "    save_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "    # 確認檔案路徑，並檢查是否有重複檔名\n",
        "    file_path = save_path / filename\n",
        "    counter = 1\n",
        "    while file_path.exists():  # 如果檔案已經存在，就在檔名後面加數字避免覆蓋\n",
        "        stem = file_path.stem      # 不包含副檔名的部分\n",
        "        suffix = file_path.suffix  # 副檔名 (例如 .jpg)\n",
        "        file_path = save_path / f'{stem}_{counter}{suffix}'  # 產生新的檔名\n",
        "        counter += 1\n",
        "\n",
        "    try:\n",
        "        resp = req.get(img_url, headers = current_headers, timeout=10)\n",
        "        resp.raise_for_status()  # 如果狀態碼不是 200，就直接丟出錯誤\n",
        "        # 把下載回來的二進位內容寫到檔案\n",
        "        with open(file_path, 'wb') as f:\n",
        "            f.write(resp.content)\n",
        "        return file_path  # 成功時回傳圖片存放的完整路徑\n",
        "\n",
        "    except Exception as e:\n",
        "        # 如果下載失敗，回傳訊息\n",
        "        print(f'[{datetime.now()}] {img_url} -> {e}\\n')\n",
        "        return None  # 失敗就回傳 None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9wg5n6bbcQx"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgaMcyPUN3l4"
      },
      "source": [
        "## OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx4l0NLpN708"
      },
      "outputs": [],
      "source": [
        "def eocr_process(graph_path: pp, reader: easyocr.Reader) -> str:\n",
        "    '''\n",
        "    使用 EasyOCR 讀取多欄位圖片，並將結果格式化為易於 AI 提取的純文字字串\n",
        "    '''\n",
        "    if not graph_path.exists():\n",
        "        return f'Error 圖片檔案未找到於路徑: {graph_path}'\n",
        "\n",
        "    try:\n",
        "        # 1. 讀取圖片\n",
        "        image = cv2.imread(str(graph_path))\n",
        "        if image is None:\n",
        "            return 'Error 錯誤：無法讀取圖片，請檢查檔案格式或是否損壞。'\n",
        "\n",
        "        h, w, _ = image.shape # 圖片shape:高、寬、顏色；第三者為BGR，維度3，但這裡不需要使用\n",
        "\n",
        "        # 2. 執行 OCR\n",
        "        results = reader.readtext(image, detail = 1)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f'Error EasyOCR 或 OpenCV 發生錯誤: {e}'\n",
        "\n",
        "    # 2.1 **分左右兩邊區塊** 的動態參數設定================================\n",
        "    # 設置為圖片高度的 2%。如果文字很小，可能需要降低到 0.01。判斷兩個文字塊是否屬於同一行的 Y 軸距離\n",
        "    row_tolerance = h * 0.016\n",
        "\n",
        "    # 如果分隔線不在中間，例如左欄佔 60%，則設為 0.6。判斷文字塊屬於左欄還是右欄的分界線\n",
        "    center_x_factor = 0.5 # 中間分隔線判斷\n",
        "    center_x = w * center_x_factor\n",
        "\n",
        "    processed_data = [] # 用來儲存所有已經確定為一行的數據結構\n",
        "\n",
        "    # 根據 X 座標分行並標記左右欄位\n",
        "    for bbox, text, conf in results: # 座標點(共有四點左上[0]、右上[1]、右下[2]、左下[3]順時針)、文字內容、信心程度\n",
        "        # 取得邊界框的中心點 Y 和 X 座標，並且把每個bbox和text都拿出來判斷\n",
        "        y_center = (bbox[0][1] + bbox[2][1]) / 2 # 判斷辨識區塊的Y軸中心點\n",
        "        x_center = (bbox[0][0] + bbox[1][0]) / 2 # 判斷辨識區塊的X軸中心點\n",
        "\n",
        "        # 根據 X 座標判斷欄位\n",
        "        column = 'left' if x_center < center_x else 'right' # 如果該判斷區塊，落在中線左邊，則代表是左側的區塊，反之亦然\n",
        "\n",
        "        # 判斷是否為同一行\n",
        "        merged = False # 合併開關\n",
        "        for item in processed_data:\n",
        "            if abs(y_center - item['y']) < row_tolerance: # 如果Y軸和該輪的區塊Y軸中心小於判斷距離，則判定為同一句話，如果是同一行，將當前的文字塊添加到已存在的item中\n",
        "                item['texts'].append({'text': text, 'x': x_center, 'col': column, 'y' : y_center})\n",
        "                merged = True\n",
        "                break # 找到應該放到哪一行後，則跳出此輪循環\n",
        "\n",
        "        if not merged: # 如果迴圈結束都找不到匹配的行，則創建一個新的行\n",
        "            processed_data.append({\n",
        "                'y': y_center,\n",
        "                'texts': [{'text': text, 'x': x_center, 'col': column, 'y' : y_center}]\n",
        "            }) # 紀錄區塊Y軸中心點、辨識出來的文字內容、區塊X軸中心點、判斷後是left還是right\n",
        "\n",
        "    # 排序與格式化輸出\n",
        "    processed_data = sorted(processed_data, key = lambda r : r['y']) # 取出 y值進行排序\n",
        "\n",
        "    left_column_output = ''\n",
        "    right_column_output = ''\n",
        "\n",
        "    for row in processed_data:\n",
        "        # 對同一行列的文字，依 X 座標排序，判定它屬於哪一個行\n",
        "        left_texts_raw = [t for t in row['texts'] if t['col'] == 'left']\n",
        "        right_texts_raw = [t for t in row['texts'] if t['col'] == 'right']\n",
        "        # 先按 X 軸排序，若 X 相同，則用 Y 軸確保垂直順序\n",
        "        sorted_left_texts = sorted(left_texts_raw, key=lambda t: (t['x'], t['y']))\n",
        "        sorted_right_texts = sorted(right_texts_raw, key=lambda t: (t['x'], t['y']))\n",
        "\n",
        "        # 去除空白，並轉為list\n",
        "        left_texts = [t['text'] for t in sorted_left_texts if t['text'].strip() != '']\n",
        "        right_texts = [t['text'] for t in sorted_right_texts if t['text'].strip() != '']\n",
        "\n",
        "        # 將文字各自串接起來，並加上換行符號\n",
        "        if left_texts:\n",
        "             left_column_output += ' '.join(left_texts) + '\\n'\n",
        "        if right_texts:\n",
        "             right_column_output += ' '.join(right_texts) + '\\n'\n",
        "\n",
        "    # 2.2 **不分邊** 的動態參數設定================================\n",
        "    processed_data_unmerged = [] # 用來儲存所有已經確定為一行的數據結構\n",
        "    column_output = ''\n",
        "    # 設置為圖片高度的 1.1%。如果文字很小，可能需要降低到 0.01。判斷兩個文字塊是否屬於同一行的 Y 軸距離\n",
        "    row_tolerance_unmerged = h * 0.011\n",
        "\n",
        "    for bbox, text, conf in results: # 座標點(共有四點左上[0]、右上[1]、右下[2]、左下[3]順時針)、文字內容、信心程度\n",
        "        # 取得邊界框的中心點 Y 和 X 座標，並且把每個bbox和text都拿出來判斷\n",
        "        y_center = (bbox[0][1] + bbox[2][1]) / 2 # 判斷辨識區塊的Y軸中心點\n",
        "        x_center = (bbox[0][0] + bbox[1][0]) / 2 # 判斷辨識區塊的X軸中心點\n",
        "\n",
        "        column = 'center'\n",
        "\n",
        "        # 判斷是否為同一組\n",
        "        merged = False # 合併開關\n",
        "        for item in processed_data_unmerged:\n",
        "            if abs(y_center - item['y']) < row_tolerance_unmerged: # 如果Y軸和該輪的區塊Y軸中心小於判斷距離，則判定為同一句話，如果是同一行，將當前的文字塊添加到已存在的item中\n",
        "                item['texts'].append({'text': text, 'x': x_center, 'col': column, 'y' : y_center})\n",
        "                merged = True\n",
        "                break # 找到應該放到哪一行後，則跳出此輪循環\n",
        "\n",
        "        if not merged: # 如果迴圈結束都找不到匹配的行，則創建一個新的行\n",
        "            processed_data_unmerged.append({\n",
        "                'y': y_center,\n",
        "                'texts': [{'text': text, 'x': x_center, 'col': column, 'y' : y_center}]\n",
        "            }) # 紀錄區塊Y軸中心點\n",
        "    # 排序與格式化輸出\n",
        "    processed_data_unmerged = sorted(processed_data_unmerged, key = lambda r : r['y']) # 取出 y值進行排序\n",
        "\n",
        "    for row in processed_data_unmerged:\n",
        "        texts_raw = [t for t in row['texts']] # 放到list中\n",
        "        sorted_texts = sorted(texts_raw, key=lambda t: (t['x'], t['y'])) # 排序，x位置先，y位置後\n",
        "\n",
        "        # 將文字各自串接起來，並加上換行符號\n",
        "        sorted_texts_list = [t['text'] for t in sorted_texts if t['text'].strip() != '']\n",
        "        if sorted_texts_list:\n",
        "            column_output += ' '.join(sorted_texts_list) + '\\n'\n",
        "\n",
        "    # 最終輸出給 AI 的格式\n",
        "    ocr_text_output = '--- OCR 圖片內容提取結果（左右分欄）---\\n'\n",
        "    ocr_text_output += '\\n=== 左欄內容 (優先閱讀) ===\\n' + left_column_output.strip()\n",
        "    ocr_text_output += '\\n\\n=== 右欄內容 (次要閱讀) ===\\n' + right_column_output.strip()\n",
        "    ocr_text_output += '\\n\\n\\n=== 不分欄內容 (另外版本) ===\\n' + column_output.strip()\n",
        "    ocr_text_output += '\\n--------------------------------------'\n",
        "\n",
        "    return ocr_text_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-NBUUKANSP3"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFuJwRfjQE9G"
      },
      "outputs": [],
      "source": [
        "cwddate = datetime.strftime(datetime.today(), '%Y%m%d')\n",
        "print(f'開始抓取，抓取資料日期 {cwddate}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTo7duBGQLZB"
      },
      "source": [
        "## 相關路徑設置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yatDHhh_mWuj"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# I. 存檔路徑 - google雲端路徑\n",
        "# ====================================================================\n",
        "drive.mount('/content/drive')\n",
        "filepath = pp(r'/content/drive/MyDrive/tibame_proj')\n",
        "\n",
        "# ====================================================================\n",
        "# II. 目標網址\n",
        "# ====================================================================\n",
        "urlpath = r'https://www.songshanculturalpark.org/exhibition'\n",
        "jpgparpath = r'https://www.songshanculturalpark.org/gallery/'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72Me7K0NTU7N"
      },
      "source": [
        "## 展覽頁面清單抓取"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikFciBcuT5It"
      },
      "source": [
        "### 環境設置 - user_agent讀取"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSnfhr-gT3lo"
      },
      "outputs": [],
      "source": [
        "# USER_AGENT = userdata.get('USER_AGENT') # 註解掉原始讀取 secrets 的方式\n",
        "\n",
        "# 從 Colab Secrets 讀取並設定為環境變數\n",
        "os.environ['USER_AGENT'] = userdata.get('USER_AGENT')\n",
        "# 從環境變數中讀取 USER_AGENT\n",
        "USER_AGENT = os.environ.get('USER_AGENT')\n",
        "\n",
        "\n",
        "hd = {'user-agent' : USER_AGENT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhbo71-yT8NN"
      },
      "source": [
        "### 連結網址抓取"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "477HuNtDck93"
      },
      "outputs": [],
      "source": [
        "res = req.get(urlpath, headers = hd)\n",
        "soup = bs(res.text, 'html.parser')\n",
        "# 展覽頁面連結\n",
        "infourl = [urljoin(urlpath, i.find('a', class_='btn')['href']) for i in soup.find_all('span', class_='row_rt')] # 等等要爬的所有網頁連結"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inpIsXpgTujn"
      },
      "source": [
        "## 每個展覽頁面內容"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rjxhv2SUMgB"
      },
      "source": [
        "### 文字資訊"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZxQJoZiTti7"
      },
      "outputs": [],
      "source": [
        "anns = baseinfo(infourl, hd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0aoKZ0mUG7q"
      },
      "source": [
        "### 圖片資訊 - OCR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0SzykbfULWw"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    ocr_reader = easyocr.Reader(['ch_tra', 'en']) # 建立模型\n",
        "    print('Info : EasyOCR 模型載入成功。')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f'Error : EasyOCR 模型載入失敗: {e}')\n",
        "    ocr_reader = None # 如果失敗，將其設置為 None\n",
        "\n",
        "for item in anns:\n",
        "    for idx, img in enumerate(item['pageimgurl']):\n",
        "        print(f'=== OCR辨識中 =========== {idx + 1} / {len(item['pageimgurl'])} ==== {item['name']} {img}') # 讀取進度條，避免我覺得他當掉了\n",
        "        ocrtext = eocr_process(img, ocr_reader) if img else None\n",
        "        item['pagetext'] += ('\\n接下來是圖片OCR內容文字，' + ocrtext) # 製作要讀取的文本內容"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1ZPTci1VLss"
      },
      "source": [
        "## 用Gemini幫我萃取一下資訊"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK8eQj2zVgJ0"
      },
      "source": [
        "### 環境設置 - gemini api key value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb691a32"
      },
      "source": [
        "# 您的專案名稱\n",
        "\n",
        "## 專案描述\n",
        "簡要說明您的專案是做什麼的，例如：\n",
        "這個專案是一個使用 Python 爬取展覽資訊、進行 OCR 文字識別並使用 Gemini API 提取結構化數據的範例專案。\n",
        "\n",
        "## 環境設定\n",
        "\n",
        "本專案需要使用到 Google Colab 環境，並依賴以下敏感資訊，這些資訊需要儲存在 Colab 的 Secrets 中：\n",
        "\n",
        "1.  **`USER_AGENT`**: 用於 HTTP 請求的 User-Agent 字串。\n",
        "2.  **`GEMINI_API_KEY`**: 您的 Google Gemini API 金鑰，用於文字分析。\n",
        "\n",
        "請依照以下步驟在您的 Colab 環境中設定 Secrets：\n",
        "\n",
        "1.  開啟您的 Colab 筆記本。\n",
        "2.  在左側面板中，點擊「🔑 密鑰」圖標。\n",
        "3.  點擊「新增密鑰」。\n",
        "4.  在「名稱」欄位輸入 `USER_AGENT`，在「值」欄位輸入您的 User-Agent 字串。點擊「儲存」。\n",
        "5.  再次點擊「新增密鑰」。\n",
        "6.  在「名稱」欄位輸入 `GEMINI_API_KEY`，在「值」欄位輸入您的 Gemini API 金鑰。點擊「儲存」。\n",
        "7.  確保在筆記本中執行了讀取 Secrets 並設定環境變數的程式碼單元。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bs_0wlHiVRC1"
      },
      "outputs": [],
      "source": [
        "# GEMINI_KEY = userdata.get('GEMINI_API_KEY') # 註解掉原始讀取 secrets 的方式\n",
        "\n",
        "# 從 Colab Secrets 讀取並設定為環境變數\n",
        "os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
        "# 從環境變數中讀取 GEMINI_API_KEY\n",
        "GEMINI_KEY = os.environ.get('GEMINI_API_KEY')\n",
        "\n",
        "client = genai.Client(api_key = GEMINI_KEY)\n",
        "\n",
        "exteninfo = [] # 用來儲存提取到的結構化數據\n",
        "cantcatch = [] # 沒有抓到的資料記錄用\n",
        "MAX_RETRIES = 5  # 設定最大重試次數\n",
        "INITIAL_DELAY = 10 # 剛開始的等待秒數\n",
        "\n",
        "class EmptyResponseError(Exception):\n",
        "    '''自定義錯誤：當 API 回傳空的文字內容時拋出。'''\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABf-6igIVvXm"
      },
      "source": [
        "### 統一Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esFPGQGMV3cJ"
      },
      "outputs": [],
      "source": [
        "# 定義 結構化產出 (Structured Output): 強制 Gemini在處理一段文字資訊後，必須以一個固定且可預測的 JSON 格式回傳結果，而不是自由形式的文字。\n",
        "extraction_schema = types.Schema(\n",
        "    type = types.Type.OBJECT, # 使用 OBJECT 作為單一活動的容器\n",
        "    properties = {\n",
        "        'name': types.Schema(type = types.Type.STRING, description = '活動的主要名稱或標題。'),\n",
        "\n",
        "        'wrktime': types.Schema(type = types.Type.STRING, description = '活動的開放或營業時間，需包含不同日期的變化和最後入場時間的說明，請統一使用 24 小時制，例如 **10:00 - 17:00**。'),\n",
        "\n",
        "        'price': types.Schema(type = types.Type.STRING, description = '票務或入場資訊，如果免費請寫 **免費入場**。'),\n",
        "\n",
        "        'note': types.Schema(type = types.Type.STRING, description = '如果展覽是多個項目組成，則將各自的資訊存放於此，需要的內容為**名稱(name)**、**日期(date)**、**時間(wrktime)**、**票價(price)**'),\n",
        "\n",
        "        'url': types.Schema(\n",
        "            type = types.Type.ARRAY,\n",
        "            description = '活動相關的所有重要網址(官網、FB、購票連結等)。',\n",
        "            items = types.Schema(type = types.Type.STRING, description = '完整的 URL。') # URL 字串的陣列\n",
        "        )\n",
        "    },\n",
        "    required = ['name', 'wrktime', 'price'] # 必要欄位\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeqhNJ6jWPCk"
      },
      "source": [
        "### Prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lOMOC3pWTYj"
      },
      "outputs": [],
      "source": [
        "base_prompt = '''\n",
        "您是一位專業的數據分析師，以及展覽策展人員。您的任務是從提供的單一文本內容中，識別並嚴格提取所有活動資訊(只要展演活動，不要優惠資訊)。\n",
        "1.請將提取的結果封裝為單一個 JSON 物件，並遵循我指定的 JSON Schema 格式。\n",
        "2.請只返回 JSON 格式的內容，不要有任何多餘的解釋或文字。如果只找到部分欄位資訊，就填入這幾個欄位就好，其他填入**無資訊**。\n",
        "3.內容因為是該展覽負責人員填寫，所以寫法都不同，如果認為文本中沒有相關欄位資訊或內容是空白，則在欄位中填入**無資訊。\n",
        "4.我會一併給你該展覽提報的簡單資訊，你可以當作參考關鍵字，放在最後並用**{}**包起來。\n",
        "5.如果遇到名稱中有 **展覽攻略** 頁面，則讀取文本中最上面開頭是 **展演活動** 項下的資訊，看到開頭是**快閃限定、賣店主題、工作坊**等關鍵字，以下內容都排除。\n",
        "6.遇到展演活動內部有很多活動，請整理後用列點方式放入**備註**欄位中，列點內容包括**名稱**、**開放日期**、**開放時間**、**票價**，不要有任何多餘的解釋或文字\n",
        "\n",
        "\n",
        "以下是待分析的活動文本，以及最後用{}標住起來的該人員提供的簡單資訊：\n",
        "'''\n",
        "\n",
        "# 請模型再思考用\n",
        "CORRECTION_PROMPT = '''\n",
        "\\n[!!!] 警告：您上一次的輸出無法被解析為有效的 JSON 格式。\n",
        "請您**嚴格**重新檢查您的輸出內容，並確保它是一個**純淨、完整且符合 JSON 規範**的 JSON 字串\n",
        "(有沒有可能是少了上下中括弧或是逗點而已，請您注意這點)，請不要包含任何額外的解釋性文字或引言。謝謝！'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX2_vDQCWnCq"
      },
      "source": [
        "### 文本分析"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCb3rC36WsD4"
      },
      "outputs": [],
      "source": [
        "for item in anns:\n",
        "    current_delay = INITIAL_DELAY\n",
        "    text_content = item['pagetext'] # 頁面上的內容敘述\n",
        "    curt_name = item['name'] # 頁面上寫的展覽名稱\n",
        "\n",
        "    # 提示詞外，附上列表上的基礎資訊當作判斷依據 內部RAG工程\n",
        "    full_prompt = (base_prompt +\n",
        "                   text_content +\n",
        "                   '，這個是展覽資訊: {名稱:' + f'{item['name']}、開始時間:{item['strt_dt']}、結束時間:{item['end_dt']}、展覽說明:{item['article']}、地點{item['loc']}' + '}')\n",
        "\n",
        "    for attempt in range(MAX_RETRIES): # 開始抓取資料，每筆資料最大次數就是5次，超過就送回錯誤\n",
        "        try:\n",
        "            print(f'Info : 開始嘗試提取「{curt_name}」活動資訊 (第 {attempt + 1}/{MAX_RETRIES} 次)')\n",
        "\n",
        "            response = client.models.generate_content(\n",
        "                model = 'gemini-2.5-flash-lite', # 使用模型 針對速度和效率進行了優化，適用於較輕量級或對延遲要求高的任務\n",
        "                contents = full_prompt, # 提示詞\n",
        "                config=types.GenerateContentConfig( # 設定模型如何回應，包括輸出格式、限制和創造性程度等\n",
        "                    response_mime_type = 'application/json', # 返回json格式資料\n",
        "                    response_schema = extraction_schema, # 回應的格式按照前面定義的輸出\n",
        "                    max_output_tokens = 1024, # 限制回傳的token數量，約3-4個英文字母或半個中文字等於1個token\n",
        "                    temperature = 0.2 # 愈低的值代表模型的回答更具決定性、準確和可預測，適合需要嚴格數據提取和遵循格式的任務。較高的值則適用於寫作、創意或頭腦風暴。\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # 增加一項檢查：確保 response.text 是個字串\n",
        "            if response is None or response.text is None:\n",
        "                raise EmptyResponseError(f'Error : API 返回了空的文字內容。')\n",
        "\n",
        "            # 如果成功，跳出重試循環 ==================================================== 到這步代表有抓到資料\n",
        "            extracted_json = json.loads(response.text) # dtype dict\n",
        "            item['extrninfo'] = extracted_json # 將營業時間、票價、官網等資訊補充進去\n",
        "            print(f'Successed : 「{curt_name}」成功提取：{extracted_json.get('name', '無名稱')}')\n",
        "            time.sleep(rd.randint(5, 15))\n",
        "            break\n",
        "            # =========================================================================\n",
        "\n",
        "        except (json.JSONDecodeError, EmptyResponseError) as e: # 例外處理 - 回傳內容為空值\n",
        "            if attempt < MAX_RETRIES - 1:\n",
        "                print(f'Waring : 警告：=== 「{curt_name}」 === 模型未返回有效 JSON (錯誤：{e})。這次取得的內容是這些  {response.text}')\n",
        "                print(f'Action : 要求模型自我修正... 等待 5 秒後重試。')\n",
        "                full_prompt += CORRECTION_PROMPT # 將修正指令附加到提示詞中，請模型重新思考可能錯誤的地方\n",
        "                time.sleep(5)\n",
        "                continue # 繼續下一次重試 (帶著修正提示)\n",
        "            else:\n",
        "                print(f'Fail : JSON 格式錯誤已達最大重試次數，跳過此項目。')\n",
        "                cantcatch.append(curt_name) # 將沒有抓到的記錄起來\n",
        "                time.sleep(rd.randint(5, 15))\n",
        "                break # 抓不到啦，盡力了，走吧...\n",
        "        except APIError as e: # 例外處理 - 追蹤API問題\n",
        "            # 處理 503 等 API 錯誤\n",
        "            if attempt < MAX_RETRIES - 1 and 'UNAVAILABLE' in str(e):\n",
        "                print(f'Error : 伺服器過載 (503 錯誤)。等待 {current_delay} 秒後重試...')\n",
        "                time.sleep(current_delay)\n",
        "                current_delay *= 1.5\n",
        "                continue\n",
        "            else:\n",
        "                print(f'Fail : API 呼叫失敗，已達最大重試次數，或發生不可恢復錯誤: {e}')\n",
        "                cantcatch.append(curt_name)\n",
        "                time.sleep(rd.randint(5, 15))\n",
        "                break # 抓不到啦，盡力了，走吧...\n",
        "        except Exception as e: # 其他未知錯誤處理\n",
        "            print(f'Error : 「{curt_name}」發生未知錯誤: {e}')\n",
        "            cantcatch.append(curt_name) # 將沒有抓到的記錄起來\n",
        "            time.sleep(rd.randint(5, 15))\n",
        "            break\n",
        "    print('***************************')\n",
        "print(f'這些是沒有抓到的展覽: {cantcatch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rcVz714W20K"
      },
      "source": [
        "# Save Infomation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NVAAWwzdPu5"
      },
      "outputs": [],
      "source": [
        "rmlist = ['big_imgurl', 'pageimgurl', 'pagetext', 'extrninfo']\n",
        "\n",
        "test = copy.deepcopy(anns)\n",
        "savedata = [] # 新增一個 list 來儲存處理後的資料\n",
        "\n",
        "for ann in test:\n",
        "    for k in ['wrktime', 'price', 'note']:\n",
        "        ann[k] = ann['extrninfo'].get(k, '無資訊')\n",
        "    for j in rmlist:\n",
        "        if j in ann: # 檢查鍵是否存在，避免 KeyError\n",
        "            del ann[j]\n",
        "    savedata.append(ann) # 將處理後的字典添加到列表中\n",
        "else:\n",
        "    print(f'Warning: 跳過 {ann.get(\"name\", \"Unnamed item\")}，內容沒有extrninfo欄位')\n",
        "\n",
        "output_filename = f'exhibition_info_{datetime.strftime(datetime.today(), \"%Y_%m_%d\")}.json'\n",
        "output_path = filepath / output_filename\n",
        "\n",
        "with open(output_path, encoding = 'utf-8', mode = 'w') as f:\n",
        "        json.dump(savedata, f, indent = 4, ensure_ascii = False)\n",
        "\n",
        "# 原始的列印迴圈可以選擇保留或移除，這裡保留供參考\n",
        "# for item in processed_data:\n",
        "#     for key, value in item.items():\n",
        "#         print(f'{key} : {value}')\n",
        "#     print('****************************')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AgaMcyPUN3l4"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}